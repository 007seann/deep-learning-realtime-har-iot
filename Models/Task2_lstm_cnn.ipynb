{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-03 10:53:29.754897: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-03 10:53:30.010873: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-11-03 10:53:30.010942: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-11-03 10:53:31.179320: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-03 10:53:31.179398: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-03 10:53:31.179404: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.fft import fft, ifft\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import entropy, iqr, kurtosis, mode, skew\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import (Activation, BatchNormalization, Bidirectional,\n",
    "                                     Conv1D, Conv2D, Dense, Dropout,\n",
    "                                     Flatten, GlobalAveragePooling1D, LSTM,\n",
    "                                     MaxPool1D, MaxPooling2D, Reshape,\n",
    "                                     TimeDistributed)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "from pandas import read_csv, unique\n",
    "from scipy.signal import argrelextrema, butter, find_peaks, lfilter, lfilter_zi\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "from kerastuner import RandomSearch, Hyperband\n",
    "import kerastuner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lying down right|hyperventilating']\n",
      "[array(['coughing', 'hyperventilating', 'normal'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "X_respeck = pickle.load(open(\"X_respeck_resp\", \"rb\"))\n",
    "y_respeck = pickle.load(open(\"y_respeck_resp\", \"rb\"))\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "# remove the physical activity label from y- can be left if wanted\n",
    "y_respeck = [[x[0].split('|')[1]] for x in y_respeck]\n",
    "enc_fitted = enc.fit(y_respeck)\n",
    "enc_fitted.categories_\n",
    "\n",
    "y_respeck = enc.transform(y_respeck).toarray()\n",
    "print(enc_fitted.categories_)# One Hot is inexed as this array prints!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X_respeck, y_respeck, test_size=0.2, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=hp.Int('lstm_units1', min_value=16, max_value=256, step=16), return_sequences=True, input_shape=X_train[0].shape, activation='relu'))\n",
    "    model.add(LSTM(units=hp.Int('lstm_units2', min_value=16, max_value=256, step=16), return_sequences=True, activation='relu'))\n",
    "    model.add(Conv1D(filters=hp.Int('conv1d_filters1', min_value=16, max_value=256, step=16), kernel_size=hp.Int('conv1d_kernel_size1', min_value=2, max_value=5), activation='relu', strides=2))\n",
    "    model.add(MaxPool1D(pool_size=hp.Int('maxpool1d_pool_size', min_value=2, max_value=5), padding='same'))\n",
    "    model.add(Conv1D(filters=hp.Int('conv1d_filters2', min_value=16, max_value=256, step=16), kernel_size=hp.Int('conv1d_kernel_size2', min_value=2, max_value=5), activation='relu', strides=1))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(BatchNormalization(epsilon=1e-06))\n",
    "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "    # Compile the model with tunable hyperparameters\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')),\n",
    "        loss=categorical_crossentropy,\n",
    "        metrics=['categorical_accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners import BayesianOptimization\n",
    "\n",
    "tuner = Hyperband(\n",
    "    build_model,\n",
    "    factor=3,  # Reduction factor for the number of models in each bracket\n",
    "    max_epochs=20,  # Maximum number of training epochs for each model\n",
    "    objective='categorical_accuracy',  # The metric to optimize\n",
    "    directory='tuner_dir',  # Directory to store results\n",
    "    project_name='Task_1_larger_lstm', # Name of the tuning project\n",
    ")\n",
    "\n",
    "\n",
    "# tuner = BayesianOptimization(\n",
    "#     build_model,\n",
    "#     objective='categorical_accuracy',  # The metric to optimize\n",
    "#     max_trials=10,  # Number of trials\n",
    "#     # num_initial_points=5,  # Number of initial random trials\n",
    "#     directory='tuner_dir',  # Directory to store results\n",
    "#     project_name='task2_larger_lstm_2'  # Name of the tuning project\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 01m 24s]\n",
      "categorical_accuracy: 0.5982314348220825\n",
      "\n",
      "Best categorical_accuracy So Far: 0.623055636882782\n",
      "Total elapsed time: 00h 07m 48s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, validation_data=(X_val, y_val), batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "294/294 [==============================] - 66s 218ms/step - loss: 0.6695 - categorical_accuracy: 0.6819 - val_loss: 0.8369 - val_categorical_accuracy: 0.5347\n",
      "Epoch 2/40\n",
      "294/294 [==============================] - 63s 213ms/step - loss: 0.6426 - categorical_accuracy: 0.7042 - val_loss: 1.2429 - val_categorical_accuracy: 0.3357\n",
      "Epoch 3/40\n",
      "294/294 [==============================] - 60s 202ms/step - loss: 0.6477 - categorical_accuracy: 0.7001 - val_loss: 0.8941 - val_categorical_accuracy: 0.4248\n",
      "Epoch 4/40\n",
      "294/294 [==============================] - 61s 206ms/step - loss: 0.6062 - categorical_accuracy: 0.7230 - val_loss: 0.7147 - val_categorical_accuracy: 0.6758\n",
      "Epoch 5/40\n",
      "294/294 [==============================] - 63s 215ms/step - loss: 0.5944 - categorical_accuracy: 0.7312 - val_loss: 0.9356 - val_categorical_accuracy: 0.5658\n",
      "Epoch 6/40\n",
      "294/294 [==============================] - 63s 216ms/step - loss: 0.5724 - categorical_accuracy: 0.7407 - val_loss: 0.6178 - val_categorical_accuracy: 0.7162\n",
      "Epoch 7/40\n",
      "294/294 [==============================] - 64s 217ms/step - loss: 0.5501 - categorical_accuracy: 0.7527 - val_loss: 0.6034 - val_categorical_accuracy: 0.7205\n",
      "Epoch 8/40\n",
      "294/294 [==============================] - 62s 212ms/step - loss: 0.5346 - categorical_accuracy: 0.7581 - val_loss: 0.5962 - val_categorical_accuracy: 0.6954\n",
      "Epoch 9/40\n",
      "294/294 [==============================] - 60s 206ms/step - loss: 0.5300 - categorical_accuracy: 0.7637 - val_loss: 0.5794 - val_categorical_accuracy: 0.7346\n",
      "Epoch 10/40\n",
      "294/294 [==============================] - 60s 204ms/step - loss: 0.4798 - categorical_accuracy: 0.7892 - val_loss: 0.5121 - val_categorical_accuracy: 0.7661\n",
      "Epoch 11/40\n",
      "294/294 [==============================] - 60s 205ms/step - loss: 0.4338 - categorical_accuracy: 0.8079 - val_loss: 0.4189 - val_categorical_accuracy: 0.8326\n",
      "Epoch 12/40\n",
      "294/294 [==============================] - 60s 204ms/step - loss: 0.4091 - categorical_accuracy: 0.8201 - val_loss: 0.4437 - val_categorical_accuracy: 0.8061\n",
      "Epoch 13/40\n",
      "294/294 [==============================] - 60s 203ms/step - loss: 0.3870 - categorical_accuracy: 0.8304 - val_loss: 0.4341 - val_categorical_accuracy: 0.8112\n",
      "Epoch 14/40\n",
      "294/294 [==============================] - 61s 206ms/step - loss: 0.3689 - categorical_accuracy: 0.8400 - val_loss: 0.3547 - val_categorical_accuracy: 0.8581\n",
      "Epoch 15/40\n",
      "294/294 [==============================] - 60s 205ms/step - loss: 0.3515 - categorical_accuracy: 0.8491 - val_loss: 0.3729 - val_categorical_accuracy: 0.8419\n",
      "Epoch 16/40\n",
      "294/294 [==============================] - 60s 205ms/step - loss: 0.3372 - categorical_accuracy: 0.8549 - val_loss: 1.0188 - val_categorical_accuracy: 0.6246\n",
      "Epoch 17/40\n",
      "294/294 [==============================] - 60s 205ms/step - loss: 0.3240 - categorical_accuracy: 0.8626 - val_loss: 0.3599 - val_categorical_accuracy: 0.8522\n",
      "Epoch 18/40\n",
      "294/294 [==============================] - 61s 207ms/step - loss: 0.3159 - categorical_accuracy: 0.8661 - val_loss: 0.6405 - val_categorical_accuracy: 0.7175\n",
      "Epoch 19/40\n",
      "294/294 [==============================] - 63s 216ms/step - loss: 0.2963 - categorical_accuracy: 0.8780 - val_loss: 0.3585 - val_categorical_accuracy: 0.8462\n",
      "Epoch 20/40\n",
      "294/294 [==============================] - 63s 215ms/step - loss: 0.2847 - categorical_accuracy: 0.8819 - val_loss: 0.2847 - val_categorical_accuracy: 0.8833\n",
      "Epoch 21/40\n",
      "294/294 [==============================] - 63s 215ms/step - loss: 0.2751 - categorical_accuracy: 0.8829 - val_loss: 0.3267 - val_categorical_accuracy: 0.8666\n",
      "Epoch 22/40\n",
      "294/294 [==============================] - 64s 217ms/step - loss: 0.2666 - categorical_accuracy: 0.8887 - val_loss: 0.2864 - val_categorical_accuracy: 0.8781\n",
      "Epoch 23/40\n",
      "294/294 [==============================] - 60s 204ms/step - loss: 0.2524 - categorical_accuracy: 0.8948 - val_loss: 0.4327 - val_categorical_accuracy: 0.8061\n",
      "Epoch 24/40\n",
      "294/294 [==============================] - 60s 206ms/step - loss: 0.2345 - categorical_accuracy: 0.9031 - val_loss: 0.3180 - val_categorical_accuracy: 0.8743\n",
      "Epoch 25/40\n",
      "294/294 [==============================] - 61s 206ms/step - loss: 0.2371 - categorical_accuracy: 0.9040 - val_loss: 0.3045 - val_categorical_accuracy: 0.8875\n",
      "Epoch 26/40\n",
      "294/294 [==============================] - 60s 204ms/step - loss: 0.2295 - categorical_accuracy: 0.9060 - val_loss: 0.2746 - val_categorical_accuracy: 0.8884\n",
      "Epoch 27/40\n",
      "294/294 [==============================] - 60s 206ms/step - loss: 0.2131 - categorical_accuracy: 0.9120 - val_loss: 0.4012 - val_categorical_accuracy: 0.8496\n",
      "Epoch 28/40\n",
      "294/294 [==============================] - 60s 204ms/step - loss: 0.2159 - categorical_accuracy: 0.9124 - val_loss: 0.2755 - val_categorical_accuracy: 0.8816\n",
      "Epoch 29/40\n",
      "294/294 [==============================] - 57s 194ms/step - loss: 0.2008 - categorical_accuracy: 0.9171 - val_loss: 0.2640 - val_categorical_accuracy: 0.9020\n",
      "Epoch 30/40\n",
      "294/294 [==============================] - 57s 193ms/step - loss: 0.1937 - categorical_accuracy: 0.9209 - val_loss: 0.2638 - val_categorical_accuracy: 0.8862\n",
      "Epoch 31/40\n",
      "294/294 [==============================] - 57s 195ms/step - loss: 0.1965 - categorical_accuracy: 0.9211 - val_loss: 0.2255 - val_categorical_accuracy: 0.9118\n",
      "Epoch 32/40\n",
      "294/294 [==============================] - 57s 194ms/step - loss: 0.1828 - categorical_accuracy: 0.9260 - val_loss: 0.2228 - val_categorical_accuracy: 0.9190\n",
      "Epoch 33/40\n",
      "294/294 [==============================] - 58s 199ms/step - loss: 0.1774 - categorical_accuracy: 0.9284 - val_loss: 0.2351 - val_categorical_accuracy: 0.9114\n",
      "Epoch 34/40\n",
      "294/294 [==============================] - 60s 205ms/step - loss: 0.1698 - categorical_accuracy: 0.9336 - val_loss: 0.2550 - val_categorical_accuracy: 0.8956\n",
      "Epoch 35/40\n",
      "294/294 [==============================] - 60s 204ms/step - loss: 0.1670 - categorical_accuracy: 0.9354 - val_loss: 0.2098 - val_categorical_accuracy: 0.9220\n",
      "Epoch 36/40\n",
      "294/294 [==============================] - 58s 197ms/step - loss: 0.1600 - categorical_accuracy: 0.9370 - val_loss: 0.2974 - val_categorical_accuracy: 0.8969\n",
      "Epoch 37/40\n",
      "294/294 [==============================] - 59s 200ms/step - loss: 0.1711 - categorical_accuracy: 0.9367 - val_loss: 0.2350 - val_categorical_accuracy: 0.9169\n",
      "Epoch 38/40\n",
      "294/294 [==============================] - 60s 205ms/step - loss: 0.1455 - categorical_accuracy: 0.9421 - val_loss: 0.2400 - val_categorical_accuracy: 0.9029\n",
      "Epoch 39/40\n",
      "294/294 [==============================] - 60s 205ms/step - loss: 0.1378 - categorical_accuracy: 0.9470 - val_loss: 0.2456 - val_categorical_accuracy: 0.9097\n",
      "Epoch 40/40\n",
      "294/294 [==============================] - 58s 196ms/step - loss: 0.1400 - categorical_accuracy: 0.9464 - val_loss: 0.2299 - val_categorical_accuracy: 0.9203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd581cb91d0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.fit(X_train, y_train, epochs=40, batch_size=64, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Task2_with_other.json', 'w') as f:\n",
    "    f.write(best.to_json())\n",
    "best.save('Trained_Task2_with_other.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 3s 45ms/step - loss: 0.2007 - categorical_accuracy: 0.9220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2006746530532837, 0.9219948649406433]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 4s 41ms/step\n",
      "74/74 [==============================] - 2s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "task1 = keras.models.load_model('Trained_Task1_2.keras')\n",
    "\n",
    "def predict_task3(X):\n",
    "    physical_action = task1.predict(X)\n",
    "    physical_action = np.argmax(physical_action, axis=1)\n",
    "    prediction_labels = ['ascending stairs', 'descending stairs', 'lying down back',\n",
    "        'lying down on left', 'lying down on stomach', 'lying down right',\n",
    "        'miscellaneous movements', 'normal walking', 'running',\n",
    "        'shuffle walking', 'sitting', 'standing']\n",
    "    physical_prediction = [prediction_labels[i] for i in physical_action]\n",
    "    subtype_prediction = best.predict(X)\n",
    "    subtype_prediction = np.argmax(subtype_prediction, axis=1)\n",
    "    sub_activities = ['coughing', 'hyperventilating', 'normal']\n",
    "    subtype_prediction = [sub_activities[i] for i in subtype_prediction]\n",
    "    predictions = [[physical_prediction[i] + '|' + subtype_prediction[i]] for i in range(len(physical_prediction))]\n",
    "    return predictions\n",
    "    \n",
    "pred = predict_task3(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(true, pred):\n",
    "    correct = 0\n",
    "    for i in range(len(true)):\n",
    "        print(true[i], pred[i])\n",
    "        if true[i] == pred[i]:\n",
    "            correct += 1\n",
    "    return correct/len(true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdiot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
