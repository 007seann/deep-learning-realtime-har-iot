{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.fft import fft, ifft\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import entropy, iqr, kurtosis, mode, skew\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import (Activation, BatchNormalization, Bidirectional,\n",
    "                                     Conv1D, Conv2D, Dense, Dropout,\n",
    "                                     Flatten, GlobalAveragePooling1D, LSTM,\n",
    "                                     MaxPool1D, MaxPooling2D, Reshape,\n",
    "                                     TimeDistributed)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "from pandas import read_csv, unique\n",
    "from scipy.signal import argrelextrema, butter, find_peaks, lfilter, lfilter_zi\n",
    "from sklearn2pmml import sklearn2pmml\n",
    "from sklearn2pmml.pipeline import PMMLPipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_respeck = pickle.load(open(\"X_respeck\", \"rb\"))\n",
    "y_respeck = pickle.load(open(\"y_respeck\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_respeck[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X_respeck, y_respeck, test_size=0.2, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "enc = enc.fit(np.array(y_train))\n",
    "y_train = enc.transform(y_train)\n",
    "y_val = enc.transform(y_val)\n",
    "y_test = enc.transform(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(LSTM(32, return_sequences=True, input_shape=X_train[0].shape, activation='relu'))\n",
    "# model.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "# model.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "# model.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "# model.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "# model.add(GlobalAveragePooling1D())\n",
    "# model.add(BatchNormalization(epsilon=1e-06))\n",
    "# model.add(Dense(12))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "# print(model.summary())\n",
    "\n",
    "\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(\n",
    "#     X_train, y_train,\n",
    "#     epochs=10,\n",
    "#     batch_size=32,\n",
    "#     validation_split=0.1,\n",
    "#     shuffle=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_val[1].reshape(500).shape)\n",
    "# predictions = model.predict(X_val)\n",
    "# print(predictions[0])\n",
    "# predictions = np.argmax(predictions, axis=1)\n",
    "# # for i, p in enumerate(predictions):\n",
    "# #     if p == 10 or p == 11:\n",
    "# #         p = sit_stand_tree.predict(X_val[i].reshape(500).reshape(1,-1))\n",
    "# y_val_pred = np.argmax(y_val, axis=1)\n",
    "# cm = confusion_matrix(y_val_pred, predictions)\n",
    "# cm_disp = ConfusionMatrixDisplay(confusion_matrix= cm)\n",
    "# cm_disp.plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Random Forest model\n",
    "# rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# rf_model_pipeline = PMMLPipeline([\n",
    "# \t(\"classifier\", RandomForestClassifier(random_state=42))\n",
    "# ])\n",
    "\n",
    "# X_train_rf = X_train.reshape(X_train.shape[0], -1)\n",
    "# # Train the model\n",
    "# rf_model_pipeline.fit(X_train_rf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\danin\\Desktop\\ProjectCode\\PDIoT-cw3-q1\\Models\\model_creation.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danin/Desktop/ProjectCode/PDIoT-cw3-q1/Models/model_creation.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m X_train_rf \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39mreshape(X_train\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danin/Desktop/ProjectCode/PDIoT-cw3-q1/Models/model_creation.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/danin/Desktop/ProjectCode/PDIoT-cw3-q1/Models/model_creation.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m rf_model_pipeline\u001b[39m.\u001b[39;49mfit(X_train_rf, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danin/Desktop/ProjectCode/PDIoT-cw3-q1/Models/model_creation.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# create individual models\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danin/Desktop/ProjectCode/PDIoT-cw3-q1/Models/model_creation.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m cnn_lstm \u001b[39m=\u001b[39m Sequential()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    457\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    458\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    459\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    460\u001b[0m )(\n\u001b[0;32m    461\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    462\u001b[0m         t,\n\u001b[0;32m    463\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    464\u001b[0m         X,\n\u001b[0;32m    465\u001b[0m         y,\n\u001b[0;32m    466\u001b[0m         sample_weight,\n\u001b[0;32m    467\u001b[0m         i,\n\u001b[0;32m    468\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    469\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    470\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    471\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    472\u001b[0m     )\n\u001b[0;32m    473\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    474\u001b[0m )\n\u001b[0;32m    476\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 188\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    189\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\tree\\_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    929\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    930\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \n\u001b[0;32m    932\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_fit(\n\u001b[0;32m    960\u001b[0m         X,\n\u001b[0;32m    961\u001b[0m         y,\n\u001b[0;32m    962\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    963\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    964\u001b[0m     )\n\u001b[0;32m    965\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    445\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_model_pipeline = rf_model\n",
    "# rf_model_pipeline = PMMLPipeline([\n",
    "# \t(\"classifier\", RandomForestClassifier(random_state=42))\n",
    "# ])\n",
    "\n",
    "X_train_rf = X_train.reshape(X_train.shape[0], -1)\n",
    "# Train the model\n",
    "rf_model_pipeline.fit(X_train_rf, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# create individual models\n",
    "cnn_lstm = Sequential()\n",
    "cnn_lstm.add(LSTM(32, return_sequences=True, input_shape=X_train[0].shape, activation='relu'))\n",
    "cnn_lstm.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "cnn_lstm.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "cnn_lstm.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "cnn_lstm.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "cnn_lstm.add(GlobalAveragePooling1D())\n",
    "cnn_lstm.add(BatchNormalization(epsilon=1e-06))\n",
    "cnn_lstm.add(Dense(12))\n",
    "cnn_lstm.add(Activation('softmax'))\n",
    "cnn_lstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "cnn_lstm.fit(X_train, y_train, epochs=20, batch_size=32, verbose=1)\n",
    "\n",
    "\n",
    "x_val_rf = X_val.reshape(X_val.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the model\n",
    "print(\"Evaluate the model:\")\n",
    "# rf_results = rf_model.evaluate(x=x_val_rf, y=y_val)\n",
    "cnn_lstm_results = cnn_lstm.evaluate(x=X_val, y=y_val)\n",
    "\n",
    "# show confusion matrix\n",
    "y_pred_cnn_lstm = cnn_lstm.predict(X_val)\n",
    "y_pred_rf = rf_model_pipeline.predict(x_val_rf)\n",
    "y_pred_ensemble = np.mean(np.array([y_pred_cnn_lstm, y_pred_rf]), axis=0)\n",
    "y_pred_ensemble = np.argmax(y_pred_ensemble, axis=1)\n",
    "y_pred_cnn_lstm = np.argmax(y_pred_cnn_lstm, axis=1)\n",
    "y_pred_rf = np.argmax(y_pred_rf, axis=1)\n",
    "\n",
    "cm = confusion_matrix(np.argmax(y_val, axis =1), y_pred_ensemble)\n",
    "cm_disp = ConfusionMatrixDisplay(confusion_matrix= cm)\n",
    "cm_disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred): \n",
    "    correct_predictions = np.sum(y_true == y_pred)\n",
    "    total_predictions = len(y_true)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    return accuracy\n",
    "accuracy(y_pred_ensemble, np.argmax(y_val, axis =1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the task configuration for binary classification\n",
    "\n",
    "# # Create the RandomForestModel\n",
    "# forest = tfdf.keras.RandomForestModel( random_seed=42)\n",
    "# # Train the model\n",
    "# history = forest.fit(\n",
    "#     np.array([x.reshape(x.shape[0], -1) for x in X_train])\n",
    "# , np.argmax(y_train, axis= 1),\n",
    "#     epochs=1,\n",
    "#     batch_size=32,\n",
    "#     validation_split=0.1,\n",
    "# )\n",
    "\n",
    "# # Evaluate the model\n",
    "# evaluation = forest.evaluate(X_val, y_val)\n",
    "# print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf_model_pipeline.predict(np.array(X_val).reshape(np.array(X_val).shape[0], -1))\n",
    "y_val_pred = np.argmax(y_val, axis=1)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "cm = confusion_matrix(y_val_pred, predictions)\n",
    "cm_disp = ConfusionMatrixDisplay(confusion_matrix= cm)\n",
    "cm_disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_select_actions(actions, X, y):\n",
    "    filtered_y = []\n",
    "    filtered_X = []\n",
    "    for j, elm in enumerate(y):\n",
    "        for i in actions:\n",
    "            if elm[i] == 1:\n",
    "                onehot = np.zeros(len(actions))\n",
    "                onehot[actions.index(i)] = 1\n",
    "                filtered_y.append(onehot)\n",
    "                filtered_X.append(pd.DataFrame(X[j]))\n",
    "    return filtered_X, np.array(filtered_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stand_sit_X, stand_sit_y = get_select_actions([10,11], X_train, y_train)\n",
    "stand_sit_X_tree = np.array(stand_sit_X).reshape(np.array(stand_sit_X).shape[0], -1)\n",
    "stand_sit_y = np.argmax(stand_sit_y, axis=1)\n",
    "\n",
    "# build random decision tree model\n",
    "sit_stand_Pipeline = PMMLPipeline([\n",
    "\t(\"classifier\", RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "# rf_model_pipeline.fit(X_train_rf, y_train)\n",
    "sit_stand_Pipeline.fit(stand_sit_X_tree, stand_sit_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stand_sit_X_val, stand_sit_y_val = get_select_actions([10,11], X_val, y_val)\n",
    "\n",
    "predictions = sit_stand_Pipeline.predict(np.array(stand_sit_X_val).reshape(np.array(stand_sit_X_val).shape[0], -1))\n",
    "stand_sit_y_val = np.argmax(stand_sit_y_val, axis=1)\n",
    "\n",
    "cm = confusion_matrix(stand_sit_y_val, predictions)\n",
    "cm_disp = ConfusionMatrixDisplay(confusion_matrix= cm)\n",
    "cm_disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_stand_sit_model = tfdf.keras.RandomForestModel(num_trees=1000)\n",
    "# stand_sit_X, stand_sit_y = get_select_actions([10,11], X_train, y_train)\n",
    "# X_stand_sit_train_rf = np.array(stand_sit_X).reshape(np.array(stand_sit_X).shape[0], -1)\n",
    "# # Train the model\n",
    "# rf_stand_sit_model.compile(metrics=[\"precision\"])\n",
    "# rf_stand_sit_model.fit(X_stand_sit_train_rf, np.argmax(stand_sit_y, axis = 1), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = rf_stand_sit_model.predict(np.array(stand_sit_X_val).reshape(np.array(stand_sit_X_val).shape[0], -1))\n",
    "# predictions = np.argmax(predictions, axis=1)\n",
    "# cm = confusion_matrix(stand_sit_y_val, predictions)\n",
    "# cm_disp = ConfusionMatrixDisplay(confusion_matrix= cm)\n",
    "# cm_disp.plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(stand_sit_X_val).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model to test if the user is sitting or standing - actually bad at sit stand detection\n",
    "# model_standing = Sequential()\n",
    "# model_standing.add(LSTM(32, return_sequences=True, input_shape=stand_sit_X[0].shape, activation='relu'))\n",
    "# model_standing.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "# model_standing.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "# model_standing.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "# model_standing.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "# model_standing.add(GlobalAveragePooling1D())\n",
    "# model_standing.add(BatchNormalization(epsilon=1e-06))\n",
    "# model_standing.add(Dense(2))\n",
    "# model_standing.add(Activation('softmax'))\n",
    "\n",
    "# print(stand_sit_X[0].shape)\n",
    "# model_standing.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# history = model_standing.fit(\n",
    "#     stand_sit_X, stand_sit_y,\n",
    "#     epochs=10,\n",
    "#     batch_size=32,\n",
    "#     validation_split=0.1,\n",
    "#     shuffle=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_tree = X_test.reshape(X_val.shape[0], -1)\n",
    "# # evaluate tree on test set\n",
    "# tree_test_acc = tree.score(X_test_tree, y_val)\n",
    "# print(tree_test_acc)\n",
    "# predictions = tree.predict(X_val.reshape(X_val.shape[0], -1))\n",
    "# predictions = np.argmax(predictions, axis=1)\n",
    "# y_val_pred = np.argmax(y_val, axis=1)\n",
    "# cm = confusion_matrix(y_val_pred, predictions)\n",
    "# cm_disp = ConfusionMatrixDisplay(confusion_matrix= cm)\n",
    "# cm_disp.plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cnn_lstm.predict(X_val)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "for i, p in enumerate(predictions):\n",
    "    if p == 10 or p == 11:\n",
    "        predictions[i] = 10 + sit_stand_Pipeline.predict(X_val[i].reshape(X_val.shape[1] * X_val.shape[2]).reshape(1,-1))\n",
    "y_val_pred = np.argmax(y_val, axis=1)\n",
    "cm = confusion_matrix(y_val_pred, predictions)\n",
    "cm_disp = ConfusionMatrixDisplay(confusion_matrix= cm)\n",
    "cm_disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_val_pred, predictions))\n",
    "accuracy(predictions, np.argmax(y_val, axis =1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the model:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\danin\\Desktop\\ProjectCode\\PDIoT-cw3-q1\\Models\\model_creation.ipynb Cell 27\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danin/Desktop/ProjectCode/PDIoT-cw3-q1/Models/model_creation.ipynb#X35sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m             y_pred_ensemble[i] \u001b[39m=\u001b[39m y_pred_cnn_lstm[i]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danin/Desktop/ProjectCode/PDIoT-cw3-q1/Models/model_creation.ipynb#X35sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m y_pred_ensemble \n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/danin/Desktop/ProjectCode/PDIoT-cw3-q1/Models/model_creation.ipynb#X35sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m y_pred_ensemble \u001b[39m=\u001b[39m full_stack_model(X_val,\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danin/Desktop/ProjectCode/PDIoT-cw3-q1/Models/model_creation.ipynb#X35sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m cm \u001b[39m=\u001b[39m confusion_matrix(np\u001b[39m.\u001b[39margmax(y_val, axis \u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), y_pred_ensemble)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danin/Desktop/ProjectCode/PDIoT-cw3-q1/Models/model_creation.ipynb#X35sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m cm_disp \u001b[39m=\u001b[39m ConfusionMatrixDisplay(confusion_matrix\u001b[39m=\u001b[39m cm)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_val' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(\"Evaluate the model:\")\n",
    "# rf_results = rf_model_pipeline.evaluate(x=x_val_rf, y=y_val)\n",
    "# cnn_lstm_results = cnn_lstm.evaluate(x=X_val, y=y_val)\n",
    "# print (rf_results)\n",
    "def full_stack_model(X, alpha):\n",
    "    # show confusion matrix\n",
    "    X_rf = X.reshape(X.shape[0], -1)\n",
    "    y_pred_cnn_lstm = alpha*cnn_lstm.predict(X)\n",
    "    y_pred_rf = rf_model_pipeline.predict(X_rf)\n",
    "    y_pred_ensemble = np.mean(np.array([y_pred_cnn_lstm, y_pred_rf]), axis=0)\n",
    "    y_pred_ensemble = np.argmax(y_pred_ensemble, axis=1)\n",
    "    y_pred_cnn_lstm = np.argmax(y_pred_cnn_lstm, axis=1)\n",
    "    y_pred_rf = np.argmax(y_pred_rf, axis=1)\n",
    "\n",
    "    for i, p in enumerate(y_pred_ensemble):\n",
    "        if p == 10 or p == 11:\n",
    "            y_pred_ensemble[i] = y_pred_rf[i] # = 10 + sit_stand_Pipeline.predict(X[i].reshape(X.shape[1] * X.shape[2]).reshape(1,-1))\n",
    "        if y_pred_ensemble[i] == 0:\n",
    "            y_pred_ensemble[i] = y_pred_cnn_lstm[i]\n",
    "    return y_pred_ensemble \n",
    "        \n",
    "y_pred_ensemble = full_stack_model(X_val,1)\n",
    "cm = confusion_matrix(np.argmax(y_val, axis =1), y_pred_ensemble)\n",
    "cm_disp = ConfusionMatrixDisplay(confusion_matrix= cm)\n",
    "cm_disp.plot()\n",
    "plt.show()\n",
    "accuracy(y_pred_ensemble, np.argmax(y_val, axis =1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ = 0\n",
    "max_alpha = 0\n",
    "for alpha in np.arange(0, 2, 0.1):\n",
    "    y_pred_ensemble = full_stack_model(X_test, alpha)\n",
    "    print(alpha)\n",
    "    acc = (accuracy(y_pred_ensemble, np.argmax(y_test, axis =1)))\n",
    "    if acc > max_:\n",
    "        max_ = acc\n",
    "        max_alpha = alpha\n",
    "print(max_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_stack_model(X):\n",
    "    # show confusion matrix\n",
    "    X_rf = X.reshape(X.shape[0], -1)\n",
    "    y_pred_cnn_lstm = 1.3*cnn_lstm.predict(X)\n",
    "    y_pred_rf = rf_model_pipeline.predict(X_rf)\n",
    "    y_pred_ensemble = np.mean(np.array([y_pred_cnn_lstm, y_pred_rf]), axis=0)\n",
    "    y_pred_ensemble = np.argmax(y_pred_ensemble, axis=1)\n",
    "    # correct for known issues with sit stand detection\n",
    "    for i, p in enumerate(y_pred_ensemble):\n",
    "        if p == 10 or p == 11:\n",
    "            y_pred_ensemble[i] = np.argmax(y_pred_rf[i], axis =1)\n",
    "        if y_pred_ensemble[i] == 0:\n",
    "            y_pred_ensemble[i] = np.argmax(y_pred_cnn_lstm[i], axis =1)\n",
    "    return y_pred_ensemble \n",
    "y_pred_ensemble = full_stack_model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy(full_stack_model(X_test), np.argmax(y_test, axis =1))\n",
    "\n",
    "cm = confusion_matrix(np.argmax(y_test, axis=1), y_pred_ensemble)\n",
    "cm_disp = ConfusionMatrixDisplay(confusion_matrix= cm)\n",
    "cm_disp.plot()\n",
    "plt.show()\n",
    "accuracy(y_pred_ensemble, np.argmax(y_test, axis =1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for w in [25,50,75,100,125,150]:    \n",
    "#     X_respeck = pickle.load(open(\"X_respeck_\" + str(w), \"rb\"))\n",
    "#     y_respeck = pickle.load(open(\"y_respeck_\" + str(w), \"rb\"))\n",
    "\n",
    "#     X_train, X_temp, y_train, y_temp = train_test_split(X_respeck, y_respeck, test_size=0.2, random_state=42)\n",
    "#     X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "#     enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "#     enc = enc.fit(np.array(y_train))\n",
    "#     y_train = enc.transform(y_train)\n",
    "#     y_val = enc.transform(y_val)\n",
    "#     y_test = enc.transform(y_test)\n",
    "\n",
    "\n",
    "#     # Define the Random Forest model\n",
    "#     rf_model = RandomForestClassifier(random_state=42)\n",
    "#     X_train_rf = X_train.reshape(X_train.shape[0], -1)\n",
    "#     # Train the model\n",
    "#     rf_model.fit(X_train_rf, y_train)\n",
    "\n",
    "#     # create individual models\n",
    "#     cnn_lstm = Sequential()\n",
    "#     cnn_lstm.add(LSTM(32, return_sequences=True, input_shape=X_train[0].shape, activation='relu'))\n",
    "#     cnn_lstm.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "#     cnn_lstm.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "#     cnn_lstm.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "#     cnn_lstm.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "#     cnn_lstm.add(GlobalAveragePooling1D())\n",
    "#     cnn_lstm.add(BatchNormalization(epsilon=1e-06))\n",
    "#     cnn_lstm.add(Dense(12))\n",
    "#     cnn_lstm.add(Activation('softmax'))\n",
    "#     cnn_lstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     cnn_lstm.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "\n",
    "#     stand_sit_X, stand_sit_y = get_select_actions([10,11], X_train, y_train)\n",
    "#     stand_sit_X_tree = np.array(stand_sit_X).reshape(np.array(stand_sit_X).shape[0], -1)\n",
    "#     stand_sit_y = np.argmax(stand_sit_y, axis=1)\n",
    "\n",
    "#     # build random decision tree model\n",
    "#     sit_stand_tree = RandomForestClassifier(random_state=42)\n",
    "#     sit_stand_tree.fit(stand_sit_X_tree, stand_sit_y)\n",
    "\n",
    "\n",
    "#     def full_stack_model(X):\n",
    "#         # show confusion matrix\n",
    "#         X_rf = X.reshape(X.shape[0], -1)\n",
    "#         y_pred_cnn_lstm = 0.7*cnn_lstm.predict(X)\n",
    "#         y_pred_rf = rf_model.predict(X_rf)\n",
    "#         y_pred_ensemble = np.mean(np.array([y_pred_cnn_lstm, y_pred_rf]), axis=0)\n",
    "#         y_pred_ensemble = np.argmax(y_pred_ensemble, axis=1)\n",
    "#         y_pred_cnn_lstm = np.argmax(y_pred_cnn_lstm, axis=1)\n",
    "#         y_pred_rf = np.argmax(y_pred_rf, axis=1)\n",
    "\n",
    "#         for i, p in enumerate(y_pred_ensemble):\n",
    "#             if p == 10 or p == 11:\n",
    "#                 y_pred_ensemble[i] = 10 + sit_stand_tree.predict(X[i].reshape(X.shape[1] * X.shape[2]).reshape(1,-1))\n",
    "#         return y_pred_ensemble \n",
    "#     y_pred_ensemble = full_stack_model(X_test)\n",
    "\n",
    "#     cm = confusion_matrix(np.argmax(y_test, axis=1), y_pred_ensemble)\n",
    "#     cm_disp = ConfusionMatrixDisplay(confusion_matrix= cm)\n",
    "#     cm_disp.plot()\n",
    "#     plt.show()\n",
    "#     accuracy(y_pred_ensemble, np.argmax(y_test, axis =1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdiot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
